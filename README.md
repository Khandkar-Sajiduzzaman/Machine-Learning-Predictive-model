# ğŸ§  Agency Type Prediction using Machine Learning - Travel Insurance

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-ML-orange)
![TensorFlow](https://img.shields.io/badge/TensorFlow-Neural%20Network-orange)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Status-Completed-success)

---

## ğŸ“‹ Table of Contents
1. [Introduction](#introduction)
2. [Dataset Description](#dataset-description)
3. [Data Pre-processing](#data-pre-processing)
4. [Model Training and Evaluation](#model-training-and-evaluation)
5. [Results & Visualizations](#results--visualizations)
6. [Conclusion](#conclusion)
7. [Contributors](#contributors)
8. [Tools and Libraries](#tools-and-libraries)
9. [License](#license)

---

## ğŸ Introduction

In the modern travel industry, insurance agencies and airlines generate large volumes of data about customer policies, claims, destinations, and transactions.  
This project uses **machine learning** to classify whether a policy belongs to an **Airlines** or a **Travel Agency**.

We implemented and compared several models:
- ğŸ§® **K-Nearest Neighbors (KNN)**
- ğŸ“ˆ **Logistic Regression** *(from scratch)*
- ğŸ§  **Neural Network (Feed-Forward)**
- ğŸ¯ **K-Means Clustering** *(unsupervised)*
- ğŸ” **K-Fold Cross-Validation** *(robust evaluation)*

The goal was to explore how these algorithms handle **mixed categorical and numerical data** and how model choice affects accuracy and generalization.

---

## ğŸ“Š Dataset Description

**Source:** Google Sheets  
**Target Variable:** `Agency Type` *(Binary â€“ Airlines or Travel Agency)*

| Feature Type | Columns |
|:--------------|:-----------------------------------------------------------|
| **Numerical** | Duration, Net Sales, Commission (in value), Age |
| **Categorical** | Distribution Channel, Destination, Claim, Gender, Agency |

### ğŸ§© Preprocessing Steps:
- Dropped unnecessary columns: `Agency`, `Product Name`, `Gender` (had 45k+ nulls)
- No missing values found  
- **OneHotEncoder** â†’ categorical features  
- **LabelEncoder** â†’ Claim, Agency Type  
- **StandardScaler** â†’ numerical features  
- Train-Test Split â†’ 70% / 30%

### ğŸ” Observations:
- Dataset was **imbalanced** (more *Travel Agency* samples).
- Strong correlations among `Agency`, `Agency Type`, and `Distribution Channel`.

---

## âš™ï¸ Data Pre-processing

1. **Dropped Columns:** `Gender`, `Agency`, `Product Name`  
2. **Encoding:** Applied One-Hot and Label encoding  
3. **Scaling:** Used `StandardScaler` for normalization  
4. **Train-Test Split:** 70% training, 30% testing  

This ensured that models trained efficiently without feature dominance due to scale.

---

## ğŸ¤– Model Training and Evaluation

### 1ï¸âƒ£ Logistic Regression
**Performance:**
- Accuracy: **82%**
- Precision: 70% (Airlines), 86% (Travel Agency)
- Recall: 60% (Airlines), 90% (Travel Agency)
- ROC-AUC: **0.85**

ğŸ’¡ *Served as a baseline model â€” struggled with imbalanced classes.*

---

### 2ï¸âƒ£ K-Nearest Neighbors (KNN)
**Best K:** 3  
**Cross-Validation Accuracy:** 98.57%

**Performance:**
- Accuracy: **98.7%**
- Precision: 98% (Airlines), 99% (Travel Agency)
- Recall: 97% (Airlines), 99% (Travel Agency)
- ROC-AUC: **0.99**

ğŸ”¥ *Best overall performer â€” strong balance between both classes.*

---

### 3ï¸âƒ£ Neural Network
**Performance:**
- Accuracy: **97.47%**
- Precision: 92% (Airlines), 100% (Travel Agency)
- Recall: 99% (Airlines), 97% (Travel Agency)
- ROC-AUC: **0.90**

âš™ï¸ *Captured nonlinear patterns but required more computation time.*

---

### 4ï¸âƒ£ K-Means Clustering (Unsupervised)
Used **PCA (2D)** projection with **K=2** to visualize natural groupings between agency types.

---

## ğŸ“ˆ Results & Visualizations

### ğŸ§® Model Comparison Summary

| Model | Accuracy | ROC-AUC | Precision (Avg) | Recall (Avg) | Notes |
|:------|:---------:|:-------:|:----------------:|:-------------:|:------|
| Logistic Regression | 82% | 0.85 | 78% | 75% | Baseline linear model |
| KNN | **98.7%** | **0.99** | **98.5%** | **98%** | Best overall |
| Neural Network | 97.4% | 0.90 | 96% | 98% | Slightly behind KNN |

---

### ğŸ§  Precision vs Recall Visualization
*(Insert your precision/recall chart here)*  
```bash
ğŸ“Š Placeholder: precision_recall_comparison.png
```

### ğŸ§© Confusion Matrix Examples
*(Insert confusion matrix image for each model)*  
```bash
ğŸ§¾ Placeholder: confusion_matrix_knn.png
ğŸ§¾ Placeholder: confusion_matrix_nn.png
```

---

## ğŸ§¾ Conclusion

âœ… **KNN** achieved the **best performance** with:
- Accuracy: **98.7%**
- ROC-AUC: **0.99**
- Balanced Precision & Recall

âš™ï¸ **Neural Network** also performed strongly, capturing nonlinear dependencies effectively.  
ğŸ“‰ **Logistic Regression** was helpful as a baseline but not ideal for this mixed, imbalanced dataset.

### ğŸ’¡ Key Insights
- Distance-based models (like KNN) are powerful for scaled mixed datasets.  
- Neural networks excel at pattern recognition but need tuning.  
- Proper scaling and encoding dramatically improve model performance.

### ğŸš€ Future Work
- Handle class imbalance with oversampling/SMOTE.  
- Tune hyperparameters for the neural network.  
- Try ensemble models: **Random Forest**, **XGBoost**, or **LightGBM**.

---

## ğŸ‘¨â€ğŸ’» Contributors
**Developed by:** Khandkar Sajid  
**Institution:** BRAC University (BRACU)  
**Major:** Computer Science & Finance  
**Specialization:** Cybersecurity, Penetration Testing, and Machine Learning  

---

## ğŸ§  Tools and Libraries
- Python ğŸ  
- NumPy / Pandas  
- Matplotlib / Seaborn  
- Scikit-learn  
- TensorFlow / Keras  
- Jupyter Notebook  

---

## ğŸ“œ License
This project is licensed under the **MIT License**.  
Feel free to use, modify, and share with proper attribution.

---

â­ *If you found this project helpful, consider giving it a star on GitHub!* â­
